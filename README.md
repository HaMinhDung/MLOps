# ğŸŒ¸ Iris Classification ML API

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)

A production-ready Machine Learning API for Iris flower classification using **Random Forest** and **SVM** models with **MLflow tracking** and **Docker deployment**.

## ğŸš€ Features

- **ğŸ§  Dual ML Models**: Random Forest & SVM classifiers
- **ğŸ“Š MLflow Integration**: Complete experiment tracking and model registry
- **ğŸš€ FastAPI Backend**: High-performance REST API with automatic documentation
- **ğŸ³ Docker Ready**: Full containerization with Docker Compose
- **ğŸ“® Testing Suite**: Comprehensive API testing with Postman collection
- **ğŸ“š Documentation**: Complete API documentation with Swagger UI

## ğŸ—ï¸ Project Structure

```
iris-ml-api/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ app.py                    # FastAPI application
â”‚   â””â”€â”€ train_models_mlflow.py    # Model training with MLflow
â”œâ”€â”€ ğŸ“ tests/
â”‚   â””â”€â”€ test_api.py              # API test suite
â”œâ”€â”€ ğŸ“ docs/
â”‚   â””â”€â”€ README_DEPLOYMENT.md     # Deployment guide
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â””â”€â”€ start_mlflow.sh          # MLflow startup script
â”œâ”€â”€ ğŸ³ docker-compose.yml        # Multi-service Docker setup
â”œâ”€â”€ ğŸ³ Dockerfile               # API container definition
â”œâ”€â”€ ğŸ“¦ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“® Iris_API.postman_collection.json  # Postman test collection
â””â”€â”€ ğŸ“„ README.md                # This file
```

## ğŸ› ï¸ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Postman (optional, for testing)

### 1. Clone & Setup
```bash
git clone <your-repo-url>
cd iris-ml-api

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Train Models
```bash
python src/train_models_mlflow.py
```

### 3. Run with Docker (Recommended)
```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps
```

### 4. Access Services
- **API Swagger UI**: http://localhost:8000/docs
- **MLflow UI**: http://localhost:5000
- **API Health**: http://localhost:8000/

## ğŸ“Š API Endpoints

| Method | Endpoint | Description | Example |
|--------|----------|-------------|---------|
| `GET` | `/` | Health check | `{"status": "healthy"}` |
| `GET` | `/models/info` | Model information | Model details & features |
| `POST` | `/predict/random_forest` | Random Forest prediction | Iris classification |
| `POST` | `/predict/svm` | SVM prediction | Iris classification |
| `POST` | `/predict/both` | Both models prediction | Compare results |

### Example Request
```json
POST /predict/random_forest
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

### Example Response
```json
{
  "model_name": "Random Forest",
  "predicted_class": "setosa",
  "predicted_class_id": 0,
  "confidence": 1.0,
  "probabilities": {
    "setosa": 1.0,
    "versicolor": 0.0,
    "virginica": 0.0
  }
}
```

## ğŸ§ª Testing

### Python Test Suite
```bash
python tests/test_api.py
```

### Postman Testing
1. Import `Iris_API.postman_collection.json` into Postman
2. Set environment variable: `BASE_URL = http://localhost:8000`
3. Run the collection tests

### Manual Testing
- **Swagger UI**: http://localhost:8000/docs
- **cURL**: See examples in `docs/README_DEPLOYMENT.md`

## ğŸ“ˆ MLflow Tracking

The project includes comprehensive experiment tracking:

- **Experiments**: Model training runs with parameters and metrics
- **Model Registry**: Versioned model artifacts
- **Metrics**: Accuracy, precision, recall for both models
- **Artifacts**: Trained models, scalers, and metadata

Access MLflow UI at http://localhost:5000 to explore experiments and compare models.

## ğŸ³ Docker Deployment

### Production Deployment
```bash
# Build and deploy
docker-compose up -d

# Scale API service
docker-compose up -d --scale iris-api=3

# View logs
docker-compose logs -f iris-api

# Stop services
docker-compose down
```

### Development Mode
```bash
# Run API locally
uvicorn src.app:app --reload --host 0.0.0.0 --port 8000

# Run MLflow UI
mlflow ui --host 0.0.0.0 --port 5000
```

## ğŸ“š Model Information

### Dataset
- **Source**: Iris flower dataset (sklearn.datasets)
- **Features**: 4 numerical features (sepal & petal dimensions)
- **Classes**: 3 species (setosa, versicolor, virginica)
- **Split**: 90% training, 10% testing

### Models
1. **Random Forest**
   - 100 estimators
   - Accuracy: ~93%
   - Fast inference

2. **Support Vector Machine**
   - RBF kernel
   - Probability estimates enabled
   - Accuracy: ~93%

Both models use StandardScaler for feature normalization.

## ğŸ”§ Configuration

### Environment Variables
```bash
PYTHONPATH=/app          # Python module path
MLFLOW_TRACKING_URI=./mlruns  # MLflow storage
```

### Model Files
- Models are saved as `.pkl` files
- Scaler is saved separately
- Test data preserved for validation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes and test thoroughly
4. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ†˜ Troubleshooting

### Common Issues

**Port already in use**
```bash
# Check what's using the port
netstat -ano | findstr :8000
# Kill the process or change port in docker-compose.yml
```

**Models not found**
```bash
# Retrain models
python src/train_models_mlflow.py
```

**Docker build fails**
```bash
# Clean Docker cache
docker system prune -a
# Rebuild
docker-compose build --no-cache
```

### Getting Help
- Check `docs/README_DEPLOYMENT.md` for detailed deployment guide
- Review API documentation at http://localhost:8000/docs
- Examine logs: `docker-compose logs iris-api`

---

## ğŸ¯ Next Steps

- [ ] Add authentication & authorization
- [ ] Implement model versioning API
- [ ] Add monitoring & alerting
- [ ] Create CI/CD pipeline
- [ ] Add more ML models
- [ ] Implement A/B testing

---

**â­ Star this repo if it helped you!**
